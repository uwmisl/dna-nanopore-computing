{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math as m\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"\" # directory containing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading Data\n",
    "'''\n",
    "Y_file = np.load(os.path.join(data_dir, 'setA_10_barcodes_classes.npy'))\n",
    "X_file = np.load(os.path.join(data_dir, 'setA_10_barcodes_raw_windows.npy'))\n",
    "print('Data loaded successfully')\n",
    "\n",
    "Y_file = Y_file.flatten()\n",
    "\n",
    "window_length = 19881 \n",
    "X_file = X_file[:,:window_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train, test split\n",
    "'''\n",
    "X_train = X_file.reshape(\n",
    "        len(X_file), X_file.shape[1], 1)\n",
    "labels_train = Y_file\n",
    "\n",
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(\n",
    "        X_train, labels_train, stratify = labels_train, train_size = 0.8)\n",
    "\n",
    "X_vld, X_test, lab_vld, lab_test = train_test_split(\n",
    "    X_vld, lab_vld, stratify = lab_vld)\n",
    "\n",
    "y_tr = lab_tr.astype(int)\n",
    "y_vld = lab_vld.astype(int)\n",
    "y_test = lab_test.astype(int)\n",
    "\n",
    "print('Data split done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If gpu is available we will use it\n",
    "'''\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reshaping data\n",
    "'''\n",
    "reshape = 141\n",
    "\n",
    "X_tr = X_tr.reshape(len(X_tr),1,reshape,reshape)\n",
    "X_vld = X_vld.reshape(len(X_vld),1,reshape,reshape)\n",
    "X_test = X_test.reshape(len(X_test),1,reshape,reshape)\n",
    "print('Data reshaping done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Zipping data together and storing in trainloader objects\n",
    "'''\n",
    "train_set = list(zip(X_tr, y_tr))\n",
    "val_set = list(zip(X_vld, y_vld))\n",
    "test_set = list(zip(X_test, y_test))\t\t\t\t\t\t\t\t  \n",
    "print('Done zipping and converting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating the neural net\n",
    "'''\n",
    "best_accuracy = -float('Inf')\n",
    "best_params = []\n",
    "\n",
    "batch_size = 30\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "\t\ttrain_set, batch_size=batch_size,shuffle=True, num_workers=2)\n",
    "vldloader = torch.utils.data.DataLoader(\n",
    "\t\tval_set, batch_size=batch_size,shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "\t\ttest_set, batch_size=batch_size,shuffle=True, num_workers=2)\n",
    "\n",
    "lr = 0.001\n",
    "epochs = 250\n",
    "momentum = 0.7557312793639288\n",
    "\t\t\n",
    "O_1 = 17\n",
    "O_2 = 18\n",
    "O_3 = 32\n",
    "O_4 = 37\n",
    "\n",
    "K_1 = 3\n",
    "K_2 = 1\n",
    "K_3 = 4\n",
    "K_4 = 2\n",
    "\n",
    "KP_1 = 4\n",
    "KP_2 = 4\n",
    "KP_3 = 1\n",
    "KP_4 = 1\n",
    "\n",
    "conv_linear_out = int(m.floor((m.floor((m.floor((m.floor((m.floor((reshape - K_1 + 1)/KP_1) - \n",
    "\tK_2 + 1)/KP_2) - K_3 + 1)/KP_3) - K_4 + 1)/KP_4)**2)*O_4))\n",
    "\t\n",
    "FN_1 = 148\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1,O_1,K_1),nn.ReLU(), \n",
    "                                   nn.MaxPool2d(KP_1))\n",
    "\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(O_1,O_2,K_2),nn.ReLU(),\n",
    "                                   nn.MaxPool2d(KP_2))\n",
    "\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(O_2,O_3,K_3),nn.ReLU(),\n",
    "                                   nn.MaxPool2d(KP_3))\n",
    "\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(O_3,O_4,K_4),nn.ReLU(),\n",
    "                                   nn.MaxPool2d(KP_4))\n",
    "\n",
    "        self.fc1 = nn.Linear(conv_linear_out, FN_1, nn.Dropout(0.2))\n",
    "\n",
    "\n",
    "        self.fc2 = nn.Linear(FN_1, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = F.leaky_relu(self.conv3(x))\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        x = x.view(len(x), -1)\n",
    "        x = F.logsigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = CNN()\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "\tnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Train\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "for epoch in range(250): \n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i,data in enumerate(trainloader, 0):\n",
    "        inputs,labels = data\n",
    "        if use_cuda and torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        outputs = outputs.to(dtype = torch.float64)\n",
    "        labels = labels.to(dtype = torch.long)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Finished epoch number ' + str(epoch))\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in vldloader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += len(labels)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the validation set: %d %%' \n",
    "    % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test\n",
    "'''\n",
    "correct = 0\n",
    "total = 0\n",
    "all_true = []\n",
    "all_pred = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        all_true.extend(labels)\n",
    "        all_pred.extend(predicted)\n",
    "\n",
    "    print('Accuracy of the network on the test set: %d %%' \n",
    "    % (100 * correct / total))\n",
    "\n",
    "text_file = open(\"setA_10_barcodes_trained_cnn_results_20191015.txt\", \"w\")\n",
    "text_file.write(\"Accuracy of the network on the test set: %d %%\" % (100 * correct / total))\n",
    "text_file.close()\n",
    "\n",
    "all_true = [x.item() for x in all_true]\n",
    "all_pred = [x.item() for x in all_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Saving the trained net\n",
    "'''\n",
    "torch.save(net.state_dict(), \"setA_10_barcodes_trained_cnn_20191015.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
